# ğŸš€ nanochat - Start Here

**Training ChatGPT-style language models from scratch**

Last Updated: 2025-11-01

---

## âš¡ Quick Navigation

### I want to train on Ptolemy HPC cluster
ğŸ‘‰ **[ptolemy_slurm_docs/RESUME_HERE.md](ptolemy_slurm_docs/RESUME_HERE.md)** â­

### I want to train locally on CPU
ğŸ‘‰ **[local_cpu_docs/START_HERE_LOCAL_CPU.md](local_cpu_docs/START_HERE_LOCAL_CPU.md)** â­

### I want to browse all documentation
ğŸ‘‰ **[DOCUMENTATION_INDEX.md](DOCUMENTATION_INDEX.md)** ğŸ“š

---

## ğŸ“ Project Structure

```
slurm-nanochat/
â”œâ”€â”€ ğŸ“„ START_HERE.md              â† You are here!
â”œâ”€â”€ ğŸ“„ DOCUMENTATION_INDEX.md     â† Complete doc navigation
â”œâ”€â”€ ğŸ“„ README.md                  â† Original project README
â”œâ”€â”€ ğŸ“„ PROJECT_STATUS.md          â† Overall project status
â”œâ”€â”€ ğŸ“„ TROUBLESHOOTING.md         â† General troubleshooting
â”‚
â”œâ”€â”€ ğŸ“‚ ptolemy_slurm_docs/        â† Ptolemy HPC documentation (13 files)
â”‚   â”œâ”€â”€ README.md                 â† Folder index
â”‚   â”œâ”€â”€ RESUME_HERE.md            â† â­ Start here for Ptolemy
â”‚   â”œâ”€â”€ PTOLEMY_SETUP.md          â† Complete setup guide
â”‚   â”œâ”€â”€ QUICK_RERUN_GUIDE.md      â† Quick commands
â”‚   â””â”€â”€ ...                       â† Status, fixes, history
â”‚
â”œâ”€â”€ ğŸ“‚ local_cpu_docs/            â† Local CPU documentation (9 files)
â”‚   â”œâ”€â”€ README.md                 â† Folder index
â”‚   â”œâ”€â”€ START_HERE_LOCAL_CPU.md   â† â­ Start here for local CPU
â”‚   â”œâ”€â”€ LOCAL_CPU_QUICKSTART.md   â† Quick setup
â”‚   â”œâ”€â”€ LOCAL_CPU_TRAINING.md     â† Training guide
â”‚   â””â”€â”€ ...                       â† Analysis, comparison, troubleshooting
â”‚
â”œâ”€â”€ ğŸ“‚ scripts/                   â† Training and analysis scripts
â”‚   â”œâ”€â”€ speedrun.slurm            â† SLURM job script (Ptolemy)
â”‚   â”œâ”€â”€ local_cpu_train.py        â† Local CPU training
â”‚   â”œâ”€â”€ chat_cli.py               â† Chat interface
â”‚   â””â”€â”€ ...
â”‚
â”œâ”€â”€ ğŸ“‚ nanochat/                  â† Core codebase
â”‚   â”œâ”€â”€ gpt.py                    â† Transformer model
â”‚   â”œâ”€â”€ engine.py                 â† Training engine
â”‚   â””â”€â”€ ...
â”‚
â””â”€â”€ ğŸ“‚ logs/                      â† Training logs (generated)
```

---

## ğŸ¯ What is nanochat?

**nanochat** is a complete implementation of a ChatGPT-style language model:
- âœ… **Full pipeline:** Tokenization â†’ Pretraining â†’ Midtraining â†’ SFT
- âœ… **Production-ready:** Web UI, CLI chat, evaluations
- âœ… **Educational:** Clean, hackable codebase
- âœ… **Scalable:** 1M params (CPU) to 560M params (GPU cluster)

### This Project

This is a fork adapted for **MSU CSE8990** course with:
- âœ… Ptolemy HPC cluster support (SLURM)
- âœ… Local CPU training for development
- âœ… Comprehensive documentation
- âœ… All fixes and optimizations applied

---

## âš¡ Quick Start Guide

### Option 1: Ptolemy HPC (Recommended for Assignment)

**What you get:**
- Full 560M parameter model
- ~12 hours training time
- Professional ChatGPT-style results
- All pipeline stages

**Quick command:**
```bash
cd /scratch/ptolemy/users/$USER/slurm-nanochat
WANDB_RUN=my_run sbatch scripts/speedrun.slurm
```

**Full guide:** [ptolemy_slurm_docs/RESUME_HERE.md](ptolemy_slurm_docs/RESUME_HERE.md)

---

### Option 2: Local CPU (Great for Learning)

**What you get:**
- 1M-50M parameter models
- 5 min - 12 hours training time
- Perfect for experimentation
- Learn the code

**Quick command:**
```bash
# Tiny model (5 minutes)
python -m scripts.local_cpu_train --depth=4 --width=256 --vocab_size=512

# Small model (30 minutes)
python -m scripts.local_cpu_train --depth=6 --width=384 --vocab_size=2048
```

**Full guide:** [local_cpu_docs/START_HERE_LOCAL_CPU.md](local_cpu_docs/START_HERE_LOCAL_CPU.md)

---

## ğŸ“š Documentation Organization

### By Platform

**Ptolemy/SLURM Cluster** â†’ [`ptolemy_slurm_docs/`](ptolemy_slurm_docs/)
- Complete HPC cluster documentation
- SLURM job submission
- Full-scale training (560M params)
- 13 documentation files
- ğŸ“– [Index](ptolemy_slurm_docs/README.md)

**Local CPU Training** â†’ [`local_cpu_docs/`](local_cpu_docs/)
- Complete local training documentation
- No GPU required
- Development and experimentation
- 9 documentation files
- ğŸ“– [Index](local_cpu_docs/README.md)

### General

**Top Level** â†’ Root directory
- [README.md](README.md) - Original project README
- [PROJECT_STATUS.md](PROJECT_STATUS.md) - Overall status
- [TROUBLESHOOTING.md](TROUBLESHOOTING.md) - General issues
- [DOCUMENTATION_INDEX.md](DOCUMENTATION_INDEX.md) - Complete navigation

---

## âš ï¸ Critical Information

### For Ptolemy Users

**MUST SET WANDB_RUN!**
```bash
# âœ… CORRECT
WANDB_RUN=my_run sbatch scripts/speedrun.slurm

# âŒ WRONG - Will skip midtraining and SFT!
sbatch scripts/speedrun.slurm
```

Without `WANDB_RUN`, midtraining and SFT phases are SKIPPED!

ğŸ“– [WANDB_RUN_FIX_SUMMARY.md](ptolemy_slurm_docs/WANDB_RUN_FIX_SUMMARY.md)

### For Local CPU Users

**Start Small!**
- Tiny model (1M params) = 5 minutes âœ…
- Small model (5M params) = 30 minutes âœ…
- Medium model (15M params) = 2-3 hours âš ï¸
- Large model (50M params) = 8+ hours âš ï¸

ğŸ“– [TRAINING_COMPARISON.md](local_cpu_docs/TRAINING_COMPARISON.md)

---

## ğŸ“ For MSU CSE8990 Students

### Assignment Context
- **Course:** CSE8990 - Final Project
- **Goal:** Train and analyze Transformer model
- **Platform:** Ptolemy HPC or local CPU
- **Deliverable:** Understanding of Transformer architecture

### Recommended Approach

**Week 1: Setup & Learning**
1. Read this file (START_HERE.md)
2. Train tiny model locally (5 min)
3. Understand the codebase
4. Review [ASSIGNMENT_README.md](ASSIGNMENT_README.md)

**Week 2: Experimentation**
1. Train small model locally (30 min)
2. Experiment with hyperparameters
3. Analyze results
4. Read [LOCAL_CPU_ANALYSIS_GUIDE.md](local_cpu_docs/LOCAL_CPU_ANALYSIS_GUIDE.md)

**Week 3: Full Training**
1. Submit Ptolemy job
2. Wait ~12 hours
3. Analyze results
4. Compare with local CPU results

**Week 4: Assignment**
1. Write analysis
2. Generate visualizations
3. Complete assignment
4. Submit

---

## ğŸ”§ Common Tasks

### Training

**Ptolemy HPC:**
```bash
WANDB_RUN=my_run sbatch scripts/speedrun.slurm
```

**Local CPU (Tiny):**
```bash
python -m scripts.local_cpu_train --depth=4 --width=256 --vocab_size=512
```

**Local CPU (Small):**
```bash
python -m scripts.local_cpu_train --depth=6 --width=384 --vocab_size=2048
```

### Monitoring

**Ptolemy:**
```bash
squeue -u $USER
tail -f logs/nanochat_speedrun_*.out
```

**Local CPU:**
```bash
# Watch the console output in real-time
```

### Chat

**Ptolemy (SFT model):**
```bash
python -m scripts.chat_cli
```

**Ptolemy (Base model):**
```bash
python -m scripts.chat_cli -i mid
```

### Analysis

**Local CPU:**
```bash
python -m scripts.local_cpu_analysis
```

---

## ğŸ“Š Platform Comparison

| Feature | Ptolemy HPC | Local CPU |
|---------|-------------|-----------|
| **Model Size** | 560M params | 1M-50M params |
| **Training Time** | ~12 hours | 5 min - 12 hours |
| **Cost** | ~$150-200 | Free |
| **Setup Time** | 1-2 hours | 10 minutes |
| **Queue Time** | 0-1 hour | Immediate |
| **Quality** | Production | Experimental |
| **Best For** | Final results | Learning, testing |

---

## ğŸ†˜ Getting Help

### Documentation

1. **Quick answers:** Check appropriate "START HERE" file
2. **Comprehensive guide:** Review platform-specific docs
3. **All docs:** Browse [DOCUMENTATION_INDEX.md](DOCUMENTATION_INDEX.md)

### Troubleshooting

1. **General issues:** [TROUBLESHOOTING.md](TROUBLESHOOTING.md)
2. **Ptolemy issues:** [ptolemy_slurm_docs/](ptolemy_slurm_docs/README.md)
3. **Local CPU issues:** [local_cpu_docs/TROUBLESHOOTING_LOCAL_CPU.md](local_cpu_docs/TROUBLESHOOTING_LOCAL_CPU.md)

### Platform-Specific

**Ptolemy:**
- WANDB_RUN not set â†’ [WANDB_RUN_FIX_SUMMARY.md](ptolemy_slurm_docs/WANDB_RUN_FIX_SUMMARY.md)
- Chat not working â†’ [PTOLEMY_SETUP.md](ptolemy_slurm_docs/PTOLEMY_SETUP.md#chat-with-your-model-interactive-session)
- Job failing â†’ [QUICK_RERUN_GUIDE.md](ptolemy_slurm_docs/QUICK_RERUN_GUIDE.md)

**Local CPU:**
- Out of memory â†’ [TROUBLESHOOTING_LOCAL_CPU.md](local_cpu_docs/TROUBLESHOOTING_LOCAL_CPU.md)
- Too slow â†’ Use smaller model
- Can't find script â†’ Check you're in project root

---

## ğŸ“ Recent Updates (2025-11-01)

### What's New
- âœ… **Fixed WANDB_RUN issue** (critical for Ptolemy)
- âœ… **Organized documentation** into folders
- âœ… **Created comprehensive indexes** for easy navigation
- âœ… **Updated all Ptolemy docs** with latest fixes

### What Changed
- All Ptolemy/SLURM docs â†’ `ptolemy_slurm_docs/`
- All local CPU docs â†’ `local_cpu_docs/`
- Top-level docs cleaned up (8 files remain)
- New navigation: [DOCUMENTATION_INDEX.md](DOCUMENTATION_INDEX.md)

### Key New Files
- [START_HERE.md](START_HERE.md) - This file!
- [DOCUMENTATION_INDEX.md](DOCUMENTATION_INDEX.md) - Complete navigation
- [ptolemy_slurm_docs/RESUME_HERE.md](ptolemy_slurm_docs/RESUME_HERE.md) - Ptolemy quick start
- [local_cpu_docs/START_HERE_LOCAL_CPU.md](local_cpu_docs/START_HERE_LOCAL_CPU.md) - Local CPU quick start

---

## ğŸ‰ Ready to Begin!

Choose your path:

### ğŸ–¥ï¸ I have Ptolemy access
ğŸ‘‰ [ptolemy_slurm_docs/RESUME_HERE.md](ptolemy_slurm_docs/RESUME_HERE.md)

### ğŸ’» I want to use my laptop/desktop
ğŸ‘‰ [local_cpu_docs/START_HERE_LOCAL_CPU.md](local_cpu_docs/START_HERE_LOCAL_CPU.md)

### ğŸ“š I want to explore documentation
ğŸ‘‰ [DOCUMENTATION_INDEX.md](DOCUMENTATION_INDEX.md)

---

**Questions?** Browse the documentation or check the troubleshooting guides!

**Good luck with your training! ğŸš€**
